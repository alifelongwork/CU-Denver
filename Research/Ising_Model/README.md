# Ising Model Research
In this section of research we were interested in applying the Ising Model from statistical mechanics to networks of real neurons. The Ising Model as originally used considers the spin states of a crystal lattice structure, that, when applied to a 2-Dimensional system, yielded phase transitions for magnetism as the temperature of the crystal structure was varied. Since then, this model has been used throughout physics and more recently in biological systems. Here we are following up research performed primarily by William Bialek, in applying the Ising Model to networks of neurons. The idea here is that networks of neurons operate around points of criticality as the activity of the network transitions between phases. Here the phases may be considered areas of low and high activity but is still ambiguous in this application. Another ambiguity in the application of this model is the idea of a critical temperature, as there is no analog for temperature when applied to neural networks. Temperature in this case is just a value parameter that may be varied within the Boltzmann equation used for calculation. 

Conceptually, the idea behind the research is that the brain operates around these points of criticality. Critical points in relation to information are regions where information capacity and rate of transfer are maximized. The network also becomes more adaptable and has the ability to communicate over long ranges. These features are certainly present within the brain itself, and give a good hypothetical foundation towards the idea that its operation occurs around a critical point or critical region. To be clear, a critical point occurs only for systems where N-> &infin; while for any finite system criticality occurs across a region. The larger the system grows, the narrower that region becomes until eventually becoming a defined point such as the critical "temperature" previously mentioned. As our systems are finite, the critical point is more of a distribution across multiple parameter values such as 0.98 < T < 1.03 just as an example. Oddly enough, research shows that the critical point does tend to occur around T = 1, but this may be due to a model bias in the generation of the Lagrangian multipliers for the Ising Model and the calculations used for the Boltzmann constant. 

### Research Methods
We have approached this problem through computational methods using experimental data. The coding has primarily been performed in python using a linux based package called ConIII which stands for Convenient Interface to Inverse Ising. This provides functions useful for solving the inverse Ising problem through various methods. The main method we have applied involve the use of a Monte Carlo Histogram (MCH) and Metropolis sampling. More about the package can be found at <url>https://github.com/eltrompetero/coniii</url>. Through the use of this package we are able to generate the multipliers that correspond to the network we are analyzing. This lets us calculate the Hamiltonian energy for the network and the various states that occur over the period of time recorded from the data. This is the energy we need to find the probability, entropy, specific heat, and susceptibility where we can then potentially identify a critical region of activity. 

### Goal
By identifying the critical region we can see transitions of activity within the brain. For the experimental data we are working with, the brain activity is correlated to the motion of a mouse arm. The idea then would be to relate the critical region, if it occurs, for the Purkinje Cells to the motion of the arm. As motion is an event requiring the maximal transfer of information in a short period of time, this could confirm the idea of criticality as it applies to the brain with regard to this information capacity through the channels. While this is an idea that has been heavily researched, it has mostly focused on cortical and retinal neurons. We may expand this in to a network of Purkinje Cells. Some ideas include:

* A small subgroup may predict the behavior of the group as a whole. By splitting up the total set of cells into smaller subgroups we can look at the behavior of these groups and the correlations that exist. This becomes computationally expensive as we primarily use a set of 30 purkinje cells so there are 30 Choose 10 ways of creating groups. We settled on 256 groups of 10 cells.
  
* We can use the ideas of specific heat and susceptibility to see if a critical region exists within the Purkinje Cell network. Even though these cells do not connect to each other, they are each connected to mossy fibers as their inputs and thus share a common activation network. One issue with this is that our set of 30 cells that we primarily work with may be too small to truly identify a peak for specific heat and susceptibility. One solution to this is to use some of the small groups of Purkinje Cells that we have access to and see if there is a small peak in these sets and if that peak becomes more pronounced in the set of 30 cells.
  
* If there is any predictability possible with the Ising model, we may be able to use this to identify when a network will transition from a period of low activity to one of high activity. It may also be useful for identifying points between order and chaos where overactivation may occur within the network. We may be able to identify this by comparing results from the base set of data where no stimulus is applied to the set where the stimulus was applied over a 50 ms window during the reach activity.

### Complications
* The Ising Model is a linear model. Neural networks are highly non-linear. While the application of the linear model to a non-linear network may provide some accurate approximations, it will never be able to model or predict the network activity to more than just an approximation. A more appropriate model that still uses the idea of the Ising Model may be the kinetic Ising Model as this is a non-linear version of the Ising Model. This has been minorly explored but not fully pursued.
  
* In order to find the critical region for the network, we need to calculate the "specific heat" and "magnetic susceptibility" for the network. These are not the only methods just the primary ones considered. These are in quotes because just like temperature, there is no true analog to these values for a network of neurons. However, the idea of criticality with respect to these calculations is still valid. Critical points both occur in thermodynamics when these values approach infinity. In a network of neurons, we can use the entropy to find these values and, when plotted, should show a large peak at some parameter value which would indicate a critical region approaching a point. In order to do this we need to know the entropy, and to know that, we need to know the probability of each state occuring. The probability of each state requires the use of the normalization function known as the partition function. This partition function involves summing the Boltzmann energy for every possible state that could exist for the network. For example, this means that for a system of 10 neurons (N=10) there are 2<sup>10</sup>=1024 possible states that could occur. This becomes a large problem to solve computationally, and various work around methods have been shown to provide an approximation. However, this once again introduces an approximation into a problem that is already an approximation of a larger problem.
  
  * Some solutions to this could include the implementation of the calculations across a GPU or multiple GPUs where one can utilize 4000+ cores within a single GPU in order to carry out the calculations. While this may still be time consuming, it may provide more accurate calculations if proven to be possible. This would involve the adaptation of the ConIII source code to a version that uses CUDA via CuPy or PyCuda. This implementation is in progress.
